## 语法分析
语法分析的目的是在词法分析结果的基础上，进一步得到解析树(Parsing Tree)。

## 上下文无关语法与解析树
一个例子：
```
S -> S ; S | ID := E | PRINT(L)
E -> ID | NAT | E + E | ( E )
L -> E | L, E
```

上下文无关文法（**Context-Free Grammar**，简称 **CFG**）是一种用来**描述语言结构**的形式化系统。

简单来说，你可以把它想象成一套**语法规则集**，这套规则定义了什么样的一句话或一个程序是**合法的**。它之所以被称为“上下文无关”，是因为**每条规则都是独立的**，不依赖于它所处的“上下文”环境。

你在 **上下文无关文法（CFG）** 中看到的箭头 `->` 符号，读作“**被定义为**”或“**可以由... 构成**”。

一套完整的上下文无关语法包含以下四个部分：
- **初始符号 (Initial Symbol)：** 语法的起始点，代表整个语言结构。例如，在 While 语言中通常以 `S`（语句）作为初始符号。
- **终结符集合 (Terminal Symbols)：** 语法中不可再分的最小单位。在编译器中，这些通常对应词法分析器切分出的**标记（Tokens）**，如 `ID` (变量名)、`NAT` (自然数)、`+`、`:=`、`;` 等。
- **非终结符集合 (Nonterminal Symbols)：** 语法结构中的占位符或中间变量，表示某种语法范畴。例如：`S`（语句）、`E`（表达式）、`L`（表达式列表）。
- **产生式系列 (Productions)：** 定义语法结构的规则。每个产生式的左边是一个**非终结符**，右边则是由**终结符**和**非终结符**组成的序列（可以为空）。在语法分析中通常表示为 `A -> α`。`

## 派生 Derivation
派生的定义：
- 将初始符号依据产生式不断展开，最后得到一个终结符序列的过程，称为“派生 (Derivation)”。

简单来说，派生就是根据语法规则（也就是产生式）“造句子”。派生是一个一步一步替换的过程：每次选择一个非终结符以及一个产生式（该非终结符在该产生式的左侧），然后用产生式右侧的符号序列来替换左侧的非终结符。

解析树具有下面的性质：
- 根节点为上下文无关语法的初始符号
- 每个叶子节点都是一个终结符，每个内部节点是一个非终结符。
- 每一个父节点和它的子节点们构成一条上下文无关语法中的产生式。

派生和解析树的关系：
- 一个成功的派生过程可以直观地用一棵解析树来表示，解析树中的每一个节点到其下层子节点的过程，都代表了派生过程中的一个基于产生式的替换步骤。
- 同样，根据派生过程中每一步的替换，我们也可以对应地构造出一棵解析树。

可以看到，派生和解析树之间，应当存在着某种对应关系。那么，这种对应关系是一一映射吗？不完全是，我们还需要加上一些条件。加上什么条件呢？我们后续会提到。

## 歧义与歧义的消除
在上下文无关语法中，怎么理解“歧义”这个概念？

我现在对歧义的理解：
- 对一套上下文无关语法规则，只要存在一个终结符序列，通过同一非终结符派生得到，且能最终能导致多个不同的解析树，那么这个上下文无关语法规则就是有歧义的。

> [!NOTE] 怎么理解“歧义”？如何说明 CFG 存在歧义？
> 如果同一个标记串（终结符序列）可以产生两棵不同的解析树，那么该语法是有歧义的。


如何消除歧义？通常，需要做两件事：
- 引入优先级：通过增加非终结符（如将 $E$ 拆为 $E, F, G$），来强制规定运算符的先后顺序（例如乘法比加法先算）
- 规定结合性：确定同优先级的运算符是左结合还是右结合。

上面两点说的比较抽象，我们需要知道并记住一些经典的歧义例子，以及如何消除歧义的例子，才能快速判断并解决歧义问题。



### 情况 1：加法、乘法、括号之间的运算顺序
```
E -> ID | E + E | E * E | ( E )
```

歧义的部分：`ID + ID * ID` 存在多种解读
- `(ID + ID) * ID`
- `ID + (ID * ID)`

**消除方法：引入算子优先级和结合性等级。** 来源指出，可以通过引入新的非终结符（如 $F$ 和 $G$）来强制执行优先级，并利用单侧递归（如左递归）来规定结合性,。

- **修改后的 CFG：**
    
    ```
    E -> F | E + F      (加法：优先级最低，左结合)
    F -> G | F * G      (乘法：优先级中等，左结合)
    G -> ID | ( E )     (基本项：优先级最高)
    ```
    
- **原理：** 较低优先级的运算（如 `+`）在产生式树的更上层，而较高优先级的运算（如 `*`）在更深层。通过将 $E \rightarrow E + E$ 改为 $E \rightarrow E + F$，强制了 `+` 号在同级时只能向左生长，从而消除了结合性歧义。

### 情况 2：悬空 ELSE 问题（不知道 IF 应该和哪个 ELSE 匹配）

```
S -> IF E THEN S ELSE S
S -> IF E THEN S
S -> PRINT ( E )
S -> ID := E
```
*注：仅写出歧义部分的产生式*

歧义的例子：`IF E TEHN IF E TEHN S ELSE S` 存在多种解读
- `IF E TEHN {IF E TEHN S ELSE S}`
- `IF E {TEHN IF E TEHN S} ELSE S`

**消除方法：限制 `IF` 语句的匹配结构（最近匹配原则）。** 歧义根源在于 `ELSE` 不知道该与哪个 `THEN` 匹配,。

- **消除思路：** 在 Bison 等工具中，通常通过设置**优先级**来解决：赋予 `ELSE` 比 `THEN` 更高的优先级，迫使它与最近的 `IF` 结合。
- **文法修改方案（简化版）：** 将语句分为“已匹配（Matched）”和“未匹配（Unmatched）”两类。
    
    ```
    S -> MS | US
    MS -> IF E THEN MS ELSE MS | PRINT(E) | ID := E
    US -> IF E THEN S | IF E THEN MS ELSE US
    ```
    
- **原理：** 这种结构强制 `ELSE` 必须先与最近的一个尚未配对的 `THEN` 结合，从而消除了 `IF E THEN {IF E THEN S} ELSE S` 这种错误的层次理解。

*注：也可以在 Bison 中强制规定先后顺序*

### 情况 3：前缀/单目运算符与二元运算符的范围冲突
```
E -> F | E + F
F -> G | F * G
G -> ID | (E) | *E
```

这一段 CFG 中存在歧义，歧义的根源在于 `G -> *E` 这个产生式，它让 `*` 操作符的操作数可以是包含任意低运算符的完整表达式。

歧义的例子：`*ID + ID` 存在两种不同的解读方式
- 第一种：`*(ID) + ID`，由 `E -> E + F -> G + F -> *E + F -> …… -> *ID + ID` 推理得到。
- 第二种：`*(ID + ID)`，由 `E -> F -> G -> *E -> *E + F -> …… -> *ID + ID` 推理得到。

**消除方法：限制前缀运算符的操作数范围。** 来源指出，歧义在于 $G \rightarrow *E$ 允许单目运算符 `*` 包含任意低优先级的表达式。

- **修改后的 CFG：**
    
    ```
    E -> F | E + F
    F -> G | F * G
    G -> ID | ( E ) | * G   (将 *E 改为 *G)
    ```
    
- **原理：** 通过将 `*` 的操作数限制为 $G$（最高优先级项），强制单目运算符 `*` 的绑定能力高于二元运算符 `+`。此时 `*ID + ID` 只能被解析为 `(*ID) + ID`。

### 情况 4：后缀运算符（如数组访问）的优先级冲突
```
E -> NAT | ID | E + E | E [ E ]
```

产生歧义的标记串：`ID + ID[NAT]`。
- 这个例子的歧义在于，它有两种可能的解读方式，我们用括号来表示。
- 第一种：`ID + (ID[NAT])`，即先进行“取数组元素”的运算。
- 第二种：`(ID + ID)[NAT]`，即先进行“加法”的运算。


**消除方法：建立分层的优先级结构。** 根据来源，需要让“取数组元素”先于“加法”计算。

- **修改后的 CFG：**
    
    ```
    E -> F | E + F          (加法：左结合)
    F -> G | F [ E ]        (数组访问：优先级高于加法)
    G -> ID | NAT           (原子项)
    ```
    
- **原理：** 数组访问产生式 $F \rightarrow F[E]$ 位于加法产生式 $E \rightarrow E + F$ 的下层。这意味着在解析 `ID + ID[NAT]` 时，`ID[NAT]` 必须先被规约为 $F$，然后才能参与加法运算。

### 情况 5：序列/分号运算符的结合性冲突
```
S -> S ; S | ID := E | PRINT( E )
E -> NAT | ID | E + E
```

产生歧义的标记串：`ID := NAT ; PRINT ( NAT ) ; ID := NAT`
- 上面这个标记串中的分号有两种可能解读的方式。
- 第一种：左结合的方式，即 `(ID := NAT ; PRINT ( NAT )) ; ID := NAT`
- 第二种：右结合的方式，即 `ID := NAT ; (PRINT ( NAT ) ; ID := NAT)`


**消除方法：通过单侧递归规定分号的结合方向。** 来源提供了针对分号序列的规范写法：

- **修改后的 CFG：**
    
    ```
    S -> T | T ; S          (采用右递归实现右结合)
    T -> ID := E | PRINT(E)
    E -> F | E + F
    F -> NAT | ID
    ```
    
- **原理：** 在 $S \rightarrow T \mid T ; S$ 中，分号后的内容是一个完整的 $S$，这会导致 `A; B; C` 解析为 `A; (B; C)`。如果需要左结合（如大多数语言），则应改为 $S \rightarrow T \mid S ; T$。

### 总结

> [!NOTE]
> **理解提示：** 歧义的本质是 **“一个句子，多重语法结构”**。消除歧义的过程就像是给语言添加 **“隐形的括号”**，通过产生式的层级嵌套，强制规定哪些符号必须先“抱团”形成一个整体。

其实我不是特别明白，为什么通过引入分层就可以消除运算优先级带来的歧义？我感觉事实上确实能消除，但是我从直观上很难理解这件事情。

为什么增加非终结符、引入分层之后就能消除运算符优先级带来的歧义？让我们回到语法树的视角：
- 语法树的深度决定了运算的先后顺序。在语法树中，越靠近叶子节点（或者说，深度越深）的运算会越早被计算，越靠近根节点的计算会越晚被计算，根节点的运算则是最后一个被计算的。
- 引入分层之后，我们就可以强制规定：相对有竞争关系的运算优先级低的符号，运算优先级高的符号一定在语法树的更下层。

上面的说法还是有点抽象，来看下面这个经典的“加法-乘法”优先级规定的例子：[补充文档](PLC-3-Parser-消除歧义的直观理解.md)

但是，就算引入了上面乘法与加法的分层，但是连续加法 `ID + ID + ID` 还是有歧义，怎么解决？

通过分层，我们同样可以解决上面的问题，具体还是可以看 [补充文档](PLC-3-Parser-消除歧义的直观理解.md)

思想：
- 通过左递归解决左结合
- 通过右递归解决右结合


## 最左/最右派生
之前我们提到，可以通过派生构造解析树，也可以通过解析树构造派生，但解析树和派生之间并不是一一映射的关系。

具体来说，同一个解析树，对应不止一个派生。
- 这是因为，派生是动态过程，有时间先后的替换过程。
- 而解析树是静态的，它是一个无序的、表示最终结构的图。

同一个解析树，对应不止一个派生，意思就是，**同一个语法结构，可以有多种不同的派生顺序得到。**

我们规定两种派生顺序，它们都能和自己的解析树唯一对应。

两种常用派生：left-most derivation / right-most derivation
- 最左派生：一个派生中，如果每次都展开最左侧的非终结符，那么这个派生就是一个最左派生。
- 最右派生：一个派生中，如果每次都展开最右侧的非终结符，那么这个派生就是一个最右派生。

同一棵解析树，
- 能唯一确定一种最左派生
- 能唯一确定一种最右派生

如果一串标记串没有歧义，那么只有唯一的最左派生能生成这一标记串，同样，只有唯一的最右派生能生成这一标记串。

基于上面的理解，我们对“歧义”可以有更深层的定义：
- 有歧义：一个标记串对应多个解析树 <-> 一个标记串对应多个不同的最左派生 <-> 一个标记串对应多个不同的最右派生
- 无歧义：结构唯一 <-> 树唯一 <-> 最左派生唯一 <-> 最右派生唯一

## 规约 Reduction
规约是派生的反向过程。

我们知道：
- 派生是一个非终结符，按照产生式，逐步展开为一串标记串（也就是终结符序列）的过程。
- 那么，规约就是一串标记串（终结符序列），按照产生式（用左侧替换右侧），最终推导出文法的开始符号的过程。

> 派生是不断展开，而规约则是不断收缩。

从解析树的视角来看：
- 派生是从根节点一路向下，直到叶子节点全部是终结符。（自顶向下）
- 规约是从叶子节点一路向上，直到所有叶子节点的产生的路径在根节点交汇。（自底向上）

规约和派生之间，也存在对应关系：
- 最左规约：对应最右派生。
- 最右规约：对应最左派生。

这种对应关系也很好理解。就拿最左派生和最右规约举例子：
- 最左派生时，最左侧的非终结符是最早被展开的；换言之，越是右侧的非终结符，就越晚被展开。
- 那么，把顺序反过来（逆向时间轴，想象时间倒流），从终结符序列开始规约时，最右侧的终结符序列就是最早变回非终结符的，这正好符合最右规约的定义。

## 移入规约分析 Shift and Reduce
下面介绍的“移入规约分析”，是一个计算生成最左规约（或者说最右派生）的过程。

### 核心模型 ：扫描线
在移入规约分析中，我们构造一个虚拟的扫描线，来帮助处理标记串。
- 扫描线右侧：是尚未处理的原始世界，全部是终结符
- 扫描线左侧：是我们的“工作台”。左侧的符号可能是未处理过的原始标记，也可能是已经合并（规约）过的非终结符。

扫描线的初始位置在原始标记串的最左侧，也就是原始标记串一开始全部在扫描线右侧（这也符合我们上面的定义）。

### 两个基本动作 ：移入和规约
分析器的操作只有两种，它们决定符号如何在扫描线两侧流动。
- 移入（Shift）：将扫描线右侧的第一个标记拿过来，放到左侧的工作台上。（lookahead，看下一个词是什么）
- 规约（Reduction）：检查工作台上**紧贴扫描线左侧的符号序列**（理解这个“紧贴”的概念很重要），如果它们正好符合某一个产生式的右部，那么就根据规则，将这一串符号“打包”并替换为该产生式左部的非终结符。

这个过程，其实很类似“俄罗斯方块”。
- 移入的过程，就是方块不断掉下来的过程。
- 规约的过程，就是掉下来的方块拼成一层或者几层，全部消掉的过程。
- 我们的目标，就是让剩下的方块尽可能少（回到初始符号）。

### 分析成功的标志
通过不断重复移入和规约两个操作，最终在工作台上只剩下唯一的初始符号，并且扫描线右侧没有剩余标记时，我们就解析成功了。

如果扫描线右侧仍然存在剩余结构，或者我们无法让工作台只剩在唯一的初始符号，那么说明分析失败。

### 冲突的产生和解决
在实际操作中，分析器可能遇到冲突的情况，即存在歧义/多种选择，不知道哪一种正确。

具体来说，冲突有下面两种：
- 移入/规约冲突：既可以继续拿右边的标记（移入），也可以把现在工作台上的符号打包（规约）。
	- 解决方式：
- 规约/规约冲突：工作台上的东西，既可以按照规则 A 打包，也可以按照规则 B 打包。
	- 解决方式：

解决方式后面会提到。

### 歧义与冲突的关系
给定一套上下文无关语法，如果移入规约分析中，一定不会出现移入/规约冲突，也不会出现规约/规约冲突，那么任何一串标记串，在该语法下，都不会产生歧义。

反之则不一定，即：上下文无关语法中不存在歧义，无法保证移入规约分析中不产生冲突。

## 已移入部分的可行性判定
### 已移入部分的结构
这里，老师的讲义里说得有些复杂，其实我们可以简单理解：
- 什么是“已移入部分”？就是扫描线左侧的内容。
- 这一部分想做什么？它们想变成某个产生式的左侧，也就是被进一步规约。
- 那这一部分实际上是什么？它们实际上是多个不同层次的产生式片段的叠加。
- 举个例子。假设当前左侧内容是 `F * (E |`（扫描线在 $E$ 之后），这部分可以被理解为多个产生式的叠加进度：
     1. 底层可能在尝试匹配 $E \rightarrow \dots$
     2. 中间层在匹配 $F \rightarrow F * \cdot G$（表示已经看到了 $F$ 和 $*$，正在等 $G$）
     3. 最表层在匹配 $G \rightarrow ( \cdot E )$（表示已经看到了 $($，正在等 $E$）。

### 基于 NFA 的判定方法
那么，既然左侧部分是由多个产生式的片段组成，我们（或者说，解析器）该怎么判断当前这个符号串“有没有前途”？即：就目前的情况来看，当前的左侧部分是否还能导向一个合法的最终结果？这就是“结构判定”的任务。

判定工具：NFA
- 通过构造一个 NFA 来判断左侧结构是否可行。

NFA 中的状态是什么？
- NFA 中的每一个状态，其实是一个“带点的产生式”。例如，$E \rightarrow E \cdot + F$ 表示“我们已经识别了 $E$，现在期待看到一个 $+$”。
- 以及，这个 NFA 中的所有状态，都是接受状态。

如何表示 NFA 中的状态变化？有两种状态转移逻辑：
- $\epsilon$ 转移：当点在非终结符之前（如 $E \rightarrow \cdot F$）时，意味着我们接下来可能看到 $F$ 能派生出的任何东西，因此可以产生一条 $\epsilon$ 边跳转到 $F$ 的所有产生式的起点（如 $F \rightarrow \cdot G$）。
- 符号转移：当我们读入（移入）一个符号或完成一次规约得到一个非终结符时，点号向后移动一位（如从 $E \rightarrow \cdot F$ 变成 $E \rightarrow F \cdot$）。

> 其实epsilon转移就有点代表“未来的可能性”。就是说，我现在可能还没做到，但是我知道我未来有可能做到，所以我可以继续跳转。只要可能性没有消失，就还不能判定“我”（扫描线左侧）是非法结构。

现在，要判断一串符号串是否是可行的扫描线左侧结构，只需判断这个符号串能否被我们按照上面的规则构造出的 NFA 所接受。

判断扫描线左侧结构是否可行，是为了在移入/规约冲突时做出选择。当然，这只是一种选择的方法，或者说，它是一种排除机制：
> 它不一定能直接告诉你该做什么，但能明确告诉你“不能做什么”。

这里需要区分两种情况：
- 移入动作的预审：分析器假装移入下一个 token，如果移入动作会导致扫描线左侧结构变得不可行，分析器就放弃移入。
- 规约动作的预审：分析器假装对当前左侧结构规约，如果规约动作会导致扫描线左侧结构变得不可行，分析器就放弃规约。
- 如果两个动作都被放弃，那么说明分析失败，显示语法错误。

当然，这两种情况的结果都是：解析器选择移入，而放弃规约。

这里还有个问题：如果移入之后，发现左侧结构不可行，那么它不能继续移入吗？可能继续移入之后，结果就可行了？会出现这种情况吗？还是这种情况根本不可能发生？

答案是，这种情况根本不可能发生。即：如果扫描线左侧结构已经被判定为“不可行”，那么继续移入更多的标记（Tokens）是不可能让它重新变得可行的。
- 是否“可行”，是基于该左侧结构能否被我们构造出的对应 NFA 所接受来判定的。
- 而 NFA 实际上已经预演了所有“未来的可能性”。如果被 NFA 判定为不可行，那么移入任何的符号，都是无法拯救这个左侧结构的。
- 所以，在移入规约分析中，如果出现扫描线左侧结构不可行的情况，那么这一标记串可以被判定为“死刑”，即移入规约分析无法完成。


### 基于 Follow 集合的判定方法
移入规约分析中还有一种判定方法，基于 Follow 集合以及 First 集合判定何时规约、何时移入。简单来说，这是一套基于符号前瞻的判定法则。

这两个集合都针对终结符计算。
- First 集合：描述了一个非终结符序列可能以哪些终结符开头。
	- 对于非终结符 Y，如果终结符 X 是 First (Y) 的元素，意味着以 X 开头的符号串（终结符序列）是有可能被规约为 Y 的。
- Follow 集合：描述了在合法的语法结构中，哪些终结符可以出现在该非终结符的右侧。
	- 对于非终结符 Y，如果终结符 X 是 Follow (Y) 的元素，意味着在某个可以被完全规约的合法句型中，X 能够紧跟在 Y 的后面（即存在 `...YX...` 的结构）。

这两个定义说起来非常绕，我还是习惯直接看形式化的定义，如下。

假设 $V_T$ 是终结符集合，$V_N$ 是非终结符集合，$S$ 是起始符号。则：

#### First 集合
对于任何文法符号 $\alpha \in (V_T \cup V_N)$： $$First(\alpha) = \{ a \in V_T \mid \alpha \Rightarrow^* a\dots \}$$ 即：**$First(\alpha)$ 是从 $\alpha$ 派生出的所有字符串中，可能出现在开头的终结符的集合。**

**计算规则：**
1. 若 $X \in V_T$，则 $First(X) = {X}$。
	- 理解：终结符不能继续派生，引起它的 First 集合中只有自己）
2. 若有产生式 $Y \rightarrow Z \dots$，则 $First(Z) \subseteq First(Y)$。
	- 理解：由于 Y 可以派生出 Z，而 Z 可以继续派生出 First(Z) 中的各种元素，说明这些元素都能被 Y 派生出来，且位于字符串开头，那么 Z 的 First 集合自然都是 Y 的 First 集合的子集

#### Follow 集合
对于任何非终结符 $A \in V_N$： $$Follow(A) = \{ a \in V_T \cup {EOF} \mid S \Rightarrow^* \dots A a \dots \}$$ 即：**$Follow(A)$ 是在所有可能的合法派生中，能够紧跟在 $A$ 之后出现的终结符的集合。**

**计算规则：**
1. 若有产生式 $U \rightarrow \dots Y Z \dots$，则 $First(Z) \subseteq Follow(Y)$。
	- 理解：非常显然。
2. 若有产生式 $Z \rightarrow \dots Y$（即 $Y$ 在产生式末尾），则 $Follow(Z) \subseteq Follow(Y)$。
	- 理解：Z 的 Follow 集合中的元素，在某个合法派生中，都可以跟在 Z 的后面；那么，把这个 Z 展开之后，结尾就变成 Y，这些元素就跟在了 Y 的后面，所以有这个包含关系。
3. 特别地，对于起始符号 $S$，$EOF \in Follow(S)$。
	- 理解：EOF 表示结束符。

#### 作用
在分析器面临“移入”还是“规约”的决策冲突时，Follow 集合提供了一个极其重要的**后置过滤条件**。其核心逻辑是：
> 对规约进行预审，当前扫描线左侧的结构能够被规约为非终结符 Y，但紧随其后的终结符 X 并不在 Follow(Y) 中，那么这次规约就是非法的，分析器必须放弃这次规约，转而选择移入。


### 总结
NFA 分析和 Follow 集合分析，都是为了构建一个确定性的语法分析器。

NFA 的分析：
- 移入动作的预审：分析器假装移入下一个 token，如果移入动作会导致扫描线左侧结构变得不可行，分析器就放弃移入。
- 规约动作的预审：分析器假装对当前左侧结构规约，如果规约动作会导致扫描线左侧结构变得不可行，分析器就放弃规约。
- 如果两个动作都被放弃，那么说明分析失败，显示语法错误。

Follow 集合分析：
- 对规约进行预审，当前扫描线左侧的结构能够被规约为非终结符 Y，但紧随其后的终结符 X 并不在 Follow (Y) 中，那么这次规约就是非法的，分析器必须放弃这次规约，转而选择移入。

## Bison 语法分析器
输入：`.y` 文件，基于 CFG 和结合性、优先级的语法分析规则
输出：`.c` 文件，用 C 语言实现的基于移入规约分析算法的语法分析器。

我们最后不是要 ParseTree，而是要 AST，但是我们前面只讲了怎么得到 ParseTree。

所以，我们在编程的过程中，直接构造抽象语法树，而不是语法解析树。语法解析树只体现在算法的过程中，而不体现在 C 程序编程的过程当中。

语法解析树上的操作，对应抽象语法树的构造操作，但不一定真的给了新的节点。

定义 while 语言的抽象语法树：
`lang.h`

AST 节点的数据结构
```c
// 定义二元运算符的类型
enum BinOpType {
    T_PLUS, T_MINUS, T_MUL, T_DIV, T_MOD,
    T_LT, T_GT, T_LE, T_GE, T_EQ, T_NE,
    T_AND, T_OR
};

// 定义一元运算符的类型
enum UnOpType {
    T_UMINUS, T_NOT
};

// 定义所有表达式的类型
enum ExprType {
    T_CONST, T_VAR,       // 常量和变量
    T_BINOP, T_UNOP,       // 二元和一元运算
    T_DEREF,              // 解引用
    T_MALLOC, T_RI, T_RC  // 内存分配、读整数、读字符
};

// 表达式结构体本身
struct expr {
    enum ExprType t; // 标记这个表达式具体是哪种类型
    union { // 根据类型的不同，存储不同的数据
        struct { unsigned int value; } CONST;  // 如果是常量, 存储其值
        struct { char *name; } VAR;             // 如果是变量, 存储其名称
        
        // 如果是二元运算, 存储运算符和左右两个子表达式
        struct {
            enum BinOpType op;
            struct expr *left;
            struct expr *right;
        } BINOP;
        
        // 如果是一元运算, 存储运算符和子表达式
        struct {
            enum UnOpType op;
            struct expr *arg;
        } UNOP;
        
        struct { struct expr *arg; } DEREF;
        struct { struct expr *arg; } MALLOC;
        struct { void *none; } RI;
        struct { void *none; } RC;
    } d;
};
```

动作/命令的 AST 结构
```c
// 定义所有命令/语句的类型
enum CmdType {
    T_DECL,     // 变量声明, e.g., var x;
    T_ASGN,     // 赋值, e.g., x := 5;
    T_SEQ,      // 顺序执行, e.g., cmd1; cmd2
    T_IF,       // if-then-else 语句
    T_WHILE,    // while 循环
    T_WI,       // Write Int 写整数
    T_WC        // Write Char 写字符
};

// 命令/语句的结构体本身
struct cmd {
    enum CmdType t; // 标记这个命令具体是哪种类型
    union { // 根据类型的不同，存储不同的数据
        struct { char *name; } DECL; // 如果是声明, 存储变量名

        // 如果是赋值, 存储左侧变量(或地址)和右侧表达式
        struct {
            struct expr *left;
            struct expr *right;
        } ASGN;

        // 如果是顺序执行, 存储前后两条命令
        struct {
            struct cmd *left;
            struct cmd *right;
        } SEQ;

        // 如果是IF语句, 存储条件、then分支和else分支
        struct {
            struct expr *cond;
            struct cmd *left;  // then 分支
            struct cmd *right; // else 分支
        } IF;

        // 如果是WHILE循环, 存储条件和循环体
        struct {
            struct expr *cond;
            struct cmd *body;
        } WHILE;

        struct { struct expr *arg; } WI;   // 如果是写整数, 存储要写的表达式
        struct { struct expr *arg; } WC;   // 如果是写字符, 存储要写的表达式
    } d;
};
```

表达式构造函数：
```c
// 创建一个常量表达式节点
struct expr *TConst(unsigned int value);

// 创建一个变量表达式节点
struct expr *TVar(char *name);

// 创建一个二元运算表达式节点
struct expr *TBinOp(enum BinOpType op, struct expr *left, struct expr *right);

// 创建一个一元运算表达式节点
struct expr *TUnOp(enum UnOpType op, struct expr *arg);

// 创建一个解引用表达式节点
struct expr *TDeref(struct expr *arg);

// 创建一个内存分配表达式节点
struct expr *TMalloc(struct expr *arg);

// 创建一个“读整数”表达式节点
struct expr *TReadInt();

// 创建一个“读字符”表达式节点
struct expr *TReadChar();
```

命令/语句构造函数：
```c
// 创建一个变量声明节点
struct cmd *TDecl(char *name);

// 创建一个赋值语句节点
struct cmd *TAsgn(struct expr *left, struct expr *right);

// 创建一个顺序执行节点
struct cmd *TSeq(struct cmd *left, struct cmd *right);

// 创建一个 if-then-else 语句节点
struct cmd *TIf(struct expr *cond, struct cmd *left, struct cmd *right);

// 创建一个 while 循环节点
struct cmd *TWhile(struct expr *cond, struct cmd *body);

// 创建一个“写整数”语句节点
struct cmd *TWriteInt(struct expr *arg);

// 创建一个“写字符”语句节点
struct cmd *TWriteChar(struct expr *arg);
```

语法分析结果在 C 中的存储
`lang.y`：Bison 语法分析器生成器的核心输入文件。
```c
/* * Part 1: C Declarations Part 
 * 包含头文件、声明全局变量和函数
 */
%{
#include <stdio.h>
#include "lang.h"
#include "lexer.h"

// 声明由 Flex 生成的词法分析函数
int yylex();
// 声明 Bison 需要的错误处理函数
int yyerror(char *str);

// 用于存储最终生成的 AST 根节点的全局变量
struct cmd *root;
%}

/* * Part 2: Bison Declarations Part 
 * 定义符号携带值的类型、声明终结符/非终结符、定义优先级等
 */

// %union 定义了所有符号可能携带的“语义值”的类型
%union {
    unsigned int n;
    char *i;
    struct expr *e;
    struct cmd *c;
    void *none;
}

// %token 声明终结符 (来自词法分析器) 及其关联的语义值类型
%token <n> TM_NAT
%token <i> TM_IDENT
%token <none> TM_LEFT_BRACE TM_RIGHT_BRACE
%token <none> TM_LEFT_PAREN TM_RIGHT_PAREN
%token <none> TM_MALLOC TM_RI TM_RC TM_WI TM_WC
%token <none> TM_VAR TM_IF TM_THEN TM_ELSE TM_WHILE TM_DO
%token <none> TM_SEMICOL TM_ASGNOP TM_OR TM_AND TM_NOT
%token <none> TM_LT TM_LE TM_GT TM_GE TM_EQ TM_NE
%token <none> TM_PLUS TM_MINUS TM_MUL TM_DIV TM_MOD

// %type 声明非终结符及其规约后生成的语义值类型
%type <c> NT_WHOLE NT_CMD
%type <e> NT_EXPR

// 优先级与结合性声明 (越往下，优先级越高)
%nonassoc TM_ASGNOP
%left TM_OR
%left TM_AND
%left TM_LT TM_LE TM_GT TM_GE TM_EQ TM_NE
%left TM_PLUS TM_MINUS
%left TM_MUL TM_DIV TM_MOD
%left TM_NOT
// %left TM_LEFT_PAREN TM_RIGHT_PAREN // 括号通常通过语法规则本身来处理优先级
// %right TM_SEMICOL // 分号通常也通过语法规则处理

%%
/* * Part 3: Grammar Rules Part 
 * 核心部分，定义了语言的上下文无关语法及对应的语义动作
 */

NT_WHOLE:
    NT_CMD {
        $$ = $1;
        root = $$; // 将最终结果存入全局变量 root
    }
;

NT_EXPR:
    TM_NAT {
        $$ = TConst($1); // 识别到一个自然数, 创建一个常量AST节点
    }
|   TM_LEFT_PAREN NT_EXPR TM_RIGHT_PAREN {
        $$ = $2; // 对于 (E)，表达式的值就是 E 本身的值
    }
|   TM_MINUS NT_EXPR {
        // 这里根据上下文，很可能代表一元负号
        $$ = TUnOp(T_UMINUS, $2); 
    }
|   NT_EXPR TM_PLUS NT_EXPR {
        // 识别到 E + E 结构, 创建一个二元操作节点
        $$ = TBinOp(T_PLUS, $1, $3);
    }
|   NT_EXPR TM_MINUS NT_EXPR {
        $$ = TBinOp(T_MINUS, $1, $3);
    }
    /* ... 此处应有其他表达式规则，如 TM_MUL, 比较运算等 ... */
;

NT_CMD:
    /* ... 此处应有所有命令/语句的语法规则，如赋值、IF、WHILE 等 ... */
;

%%
/* * Part 4: Additional C Code Part 
 * 放置需要用到的 C 语言辅助函数
 */

// 语法错误处理函数
int yyerror(char *str) {
    fprintf(stderr, "Syntax Error: %s at line %d\n", str, yylineno);
    return 0;
}

// 注：一个完整的程序通常还会在这里或另一个 .c 文件中包含 main 函数
```

Bison 和 Flex 的关系
- Flex 是词法分析器，它负责将源代码字符串处理为 Token
- Bison 是语法分析器，它负责根据我们 `.y` 文件中给出的语法规则，来自动生成一段 C 语言的语法分析程序。这个 C 程序中的 `yyparse()` 函数会不断调用 `yylex()` 来获取 Token，并且根据 `.y` 文件中的语义动作，将这些 Token 组合为一棵 AST。 


